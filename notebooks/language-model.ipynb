{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "language-model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BYU-Handwriting-Lab/GettingStarted/blob/solution/notebooks/language-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3SVor5MHLtj"
      },
      "source": [
        "# Language Model\n",
        "\n",
        "This notebook provides code to create a character-level language model in \n",
        "TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc4bV3ezKMne"
      },
      "source": [
        "### Dependencies\n",
        "\n",
        "Import the necessary dependencies and download our character set and corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibhkP7GXGwhI"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhHYfrFDKh5I"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/ericburdett/named-entity-recognition/master/char_set.json\n",
        "!wget -q --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1ZsJ8cZSDU98GpcK-kl_Cq3eTt-R2YvSJ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1ZsJ8cZSDU98GpcK-kl_Cq3eTt-R2YvSJ\" -O french_ner_dataset.csv && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBgarB6HN_-9"
      },
      "source": [
        "# ID: 1M26Gpca8Ug4YvRLxoUDDCjMBeJtojITY\n",
        "!wget -q --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wDMLz9hTmfvPhkhCHTylbeAU6Utpkqb1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1wDMLz9hTmfvPhkhCHTylbeAU6Utpkqb1\" -O french_text.txt && rm -rf /tmp/cookies.tx"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEOHweMX3i-a"
      },
      "source": [
        "## Load the Corpus\n",
        "\n",
        "Define some constants to help us know which characters are used for words and\n",
        "which are used for punctuation/digits.\n",
        "\n",
        "Load the corpus to be used for tokenization and dataset creation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moYNpZedrzLG"
      },
      "source": [
        "DEFAULT_CHARS = ' !\"#$%&\\'()*+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|~£§¨«¬\\xad' \\\n",
        "                '°²´·º»¼½¾ÀÂÄÇÈÉÊÔÖÜßàáâäæçèéêëìîïñòóôöøùúûüÿłŒœΓΖΤάήαδεηικλμνξοπρτυχψωόώІ‒–—†‡‰‹›₂₤℔⅓⅔⅕⅖⅗⅘⅙⅚⅛∆∇∫≠□♀♂✓ｆ'\n",
        "# The default list of non-punctuation characters needed for the word beam search decoding algorithm\n",
        "DEFAULT_NON_PUNCTUATION = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÀÂÄÇÈÉÊÔÖÜßàáâäæçèéêëìîïñòóôöøùúûüÿ' \\\n",
        "                          'łŒœΓΖΤάήαδεηικλμνξοπρτυχψωόώІ'\n",
        "\n",
        "DEFAULT_PUNCTUATION = string.punctuation + '0123456789'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zibqC-fN9DM"
      },
      "source": [
        "lines = open('french_text.txt', 'r', encoding='utf8').readlines()\n",
        "\n",
        "french_words = []\n",
        "for line in lines:\n",
        "    french_words.extend(line.split())\n",
        "french_words = ' '.join(french_words)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv7qG-xbv4Ll"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "One of the hardest parts is creating a good tokenization method.\n",
        "\n",
        "This tokenizer will create a token for each word. Each punctuation or digit\n",
        "character will have its own token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsm67koTOF8I"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self, corpus, word_chars, punctuation, lower=False):\n",
        "        self.word_chars = word_chars\n",
        "        self.punctuation = punctuation\n",
        "        self.regex = r\"[\" + self.word_chars + r\"]+|[^\\s]\" \n",
        "\n",
        "        words = self.split(corpus)\n",
        "        all_words_list = words + list(punctuation)\n",
        "        all_words_list_unique = list(set(all_words_list))\n",
        "        all_words = [' '.join(all_words_list_unique)]\n",
        "\n",
        "        self.total_tokens = len(all_words_list_unique) + 2 # +2 to account for 0 (reserved) and 1 (OOV)\n",
        "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.total_tokens, filters='', lower=lower, oov_token='<OOV>')\n",
        "        self.tokenizer.fit_on_texts(all_words)\n",
        "\n",
        "    def split(self, text):\n",
        "        return re.findall(self.regex, text)\n",
        "\n",
        "    def texts_to_sequences(self, text):\n",
        "        words = self.split(text)\n",
        "        return self.tokenizer.texts_to_sequences([' '.join(words)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktU759SWQ3Ov",
        "outputId": "f01b143b-3621-4f66-b016-54ed56619a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = Tokenizer(french_words, DEFAULT_NON_PUNCTUATION, DEFAULT_PUNCTUATION, lower=False)\n",
        "sentence = 'acte de deces-de..1832(hello)5eme'\n",
        "\n",
        "print('Original Sentence:', sentence)\n",
        "print('Split Sentence:', tokenizer.split(sentence))\n",
        "print('Tokenized Sentence:', tokenizer.texts_to_sequences(sentence))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Sentence: acte de deces-de..1832(hello)5eme\n",
            "Split Sentence: ['acte', 'de', 'deces', '-', 'de', '.', '.', '1', '8', '3', '2', '(', 'hello', ')', '5', 'eme']\n",
            "Tokenized Sentence: [[40723, 11811, 17855, 11916, 11811, 34176, 34176, 33369, 11084, 2654, 13378, 2522, 1, 38654, 3772, 11895]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAhBZVvgwwVX",
        "outputId": "3d897cc1-c103-4db4-df08-87d1cc5449f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedding = tf.keras.layers.Embedding(tokenizer.total_tokens, 1024)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences(sentence)\n",
        "sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=1)\n",
        "\n",
        "tf.squeeze(embedding(sequence))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1024,), dtype=float32, numpy=\n",
              "array([-0.04362495, -0.02038902,  0.01931791, ..., -0.048725  ,\n",
              "       -0.0081457 ,  0.04110047], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122a22FM3SyZ"
      },
      "source": [
        "## Dataset Creation\n",
        "\n",
        "Create the Tensorflow dataset using the tokenizer created above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py6Kz97fqYgu"
      },
      "source": [
        "def create_context_pairs(words, window_size, negative_sample_size):\n",
        "    focus_words = []\n",
        "    context_words = []\n",
        "    labels = []\n",
        "\n",
        "    # Add positive samples\n",
        "    for index in tqdm(range(len(words)), desc='Positive Samples'):\n",
        "\n",
        "        # Grab words to the left:\n",
        "        for i in range(1, window_size + 1):\n",
        "            left_index = index - i\n",
        "            if left_index >= 0:\n",
        "                focus_words.append(words[index])\n",
        "                context_words.append(words[left_index])\n",
        "                labels.append(1)\n",
        "        \n",
        "        # Grab words to the right:\n",
        "        for i in range(1, window_size + 1):\n",
        "            right_index = index + i\n",
        "            if right_index < len(words):\n",
        "                focus_words.append(words[index])\n",
        "                context_words.append(words[right_index])\n",
        "                labels.append(1)               \n",
        "    \n",
        "    # Add negative samples\n",
        "    for word in tqdm(words, desc='Negative Samples'):\n",
        "        for i in range(negative_sample_size):\n",
        "            index = random.randint(0, len(words) - 1)\n",
        "            focus_words.append(word)\n",
        "            context_words.append(words[index])\n",
        "            labels.append(0)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    print('Shuffling dataset...')\n",
        "    zipped = list(zip(focus_words, context_words, labels))\n",
        "    random.shuffle(zipped)\n",
        "    focus_words, context_words, labels = zip(*zipped)\n",
        "    print('Done.')\n",
        "    \n",
        "    return tf.constant(focus_words, dtype=tf.int32), tf.constant(context_words, dtype=tf.int32), tf.constant(labels, dtype=tf.int32)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMSAV8g4yUI",
        "outputId": "efbd0009-0860-4078-e7cb-a841eafd20c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Tokenize the entire corpus\n",
        "tokenized_french_words = tokenizer.texts_to_sequences(french_words)[0]\n",
        "\n",
        "# Create pairs of words that should be similar\n",
        "focus_words, context_words, labels = create_context_pairs(tokenized_french_words, 3, 5)\n",
        "\n",
        "# Create the dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((focus_words, context_words, labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Samples: 100%|██████████| 1086647/1086647 [00:03<00:00, 329820.29it/s]\n",
            "Negative Samples: 100%|██████████| 1086647/1086647 [00:10<00:00, 105715.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling dataset...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKcfhDSl7Wkj",
        "outputId": "f782ece8-adf0-4452-db90-c0751aa1d791",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Show one batch of 100 words\n",
        "for focus_word, context_word, label in dataset.batch(100).take(1):\n",
        "    print(focus_word)\n",
        "    print(context_word)\n",
        "    print(label)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 4671 27998    59  4620 34176 35618 26717 18712 11811  7696 12237 34176\n",
            "  2355 26298 28959 34151 33813 35400  7050 26781 32178  7696   206 10420\n",
            " 11496  8508 24171 42402 11811 34761 28959 23865 23293 31696 32178 29249\n",
            "  2624 20677 11811 11811 29249 32178 38956 21087  2522 23438 18183 28491\n",
            " 11811  1631  9206 25033  5722 34884 26191 31121  3772 36399 12624  2512\n",
            " 34761 38654  6936 32649 32063 34761  2368 41950  3778 11811 17699 40589\n",
            " 41972 39089  8287 32178 32063  8273 27188  7696 39407 32063 33369 11811\n",
            " 34890 30355  2512 11811 29237 11916 13515 15962  7785 28491 24512 39407\n",
            " 22895 11811 42402  3772], shape=(100,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[27738 34890 32145  7785 10839 34761 31573 11811 26717  9157 40723 32178\n",
            " 14090 17762 39999 23808 23606 11811 13378 34890  3845 17750 34761 33369\n",
            " 42279 38780  1575 36227 38780 31573  1465  9206 29249 13378 10532  2012\n",
            " 34449 36962 10173 30355 11811 27188 30355 20249  4511 36693 14228 13215\n",
            " 22895 27998 32443 13106 15951  1465  6469 18344 35431 26191 33369 40896\n",
            " 16341 26713 11811 20563  3722 10473 40723  8756 25264 40723  2512 20848\n",
            "  2368 11388 24773 26713  1631 11388  7696 21928  4686  6730 33369 15029\n",
            " 28959 37385 21015 30355 40723  7696  1465  2041 39930 27188  2468 10503\n",
            " 35974 35895  9888 21087], shape=(100,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0\n",
            " 1 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1\n",
            " 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 1 0 0 1], shape=(100,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "579eYIWYLm0h"
      },
      "source": [
        "### Model Creation\n",
        "\n",
        "Build our simple model that includes an embedding layer, recurrent layer, and\n",
        "dense layer to get us down to the number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnnRRSRvLI9E"
      },
      "source": [
        "class LanguageModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim=128, embedding_weights):\n",
        "        super(LanguageModel, self).__init__()\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "        self.context = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "        self.dot = tf.keras.layers.Dot(axes=(1,1))\n",
        "    \n",
        "    def call(self, target, context, training=False):\n",
        "        if training:\n",
        "            target = self.embedding(target)\n",
        "            context = self.context(context)\n",
        "            dot = self.dot([target, context])\n",
        "            out = tf.keras.activations.sigmoid(dot)\n",
        "        else:\n",
        "            target = self.embedding(target)\n",
        "            context = self.embedding(context)\n",
        "            dot = self.dot([target, context])\n",
        "            out = tf.keras.activations.sigmoid(dot)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0sp09YtmNIN"
      },
      "source": [
        "Test it out just to make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy8MOv64kKQo",
        "outputId": "57f260e8-7745-48ff-bd49-b00173e38a86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = LanguageModel(tokenizer.total_tokens)\n",
        "\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "for focus_word, context_word, label in dataset.shuffle(5000).batch(5).take(1):\n",
        "    output = model(focus_word, context_word)\n",
        "    loss = loss_fn(label, output)\n",
        "    print('Output Similarity Predictions:', output.numpy())\n",
        "    print('Output Similarity Actual', label.numpy())\n",
        "    print('Loss:', loss.numpy())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output Similarity Predictions: [[0.5001859 ]\n",
            " [0.5008042 ]\n",
            " [0.50052506]\n",
            " [0.49966443]\n",
            " [0.49489838]]\n",
            "Output Similarity Actual [0 0 0 0 1]\n",
            "Loss: 0.6956704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix0fE8BVmtJu"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "Train the model based on the text in our corpus.\n",
        "\n",
        "The goal is to predict the next character. Thus, the target is the input tensor\n",
        "rolled by one character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50RhKLmCUVgA",
        "outputId": "b7eb7152-66a3-44ee-a0fc-f05f09cd6012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TRAIN_SPLIT_SIZE = 1.0\n",
        "SHUFFLE_SIZE = 100_000\n",
        "BATCH_SIZE = 20_000\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 2e-3\n",
        "\n",
        "\n",
        "dataset_size = dataset.cardinality().numpy()\n",
        "train_dataset_size = int(dataset_size * TRAIN_SPLIT_SIZE)\n",
        "val_dataset_size = dataset_size - train_dataset_size\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = dataset.take(train_dataset_size)\\\n",
        "                    .shuffle(SHUFFLE_SIZE)\\\n",
        "                    .batch(BATCH_SIZE)\n",
        "\n",
        "val_dataset = dataset.skip(train_dataset_size)\\\n",
        "                    .batch(BATCH_SIZE)\n",
        "\n",
        "\n",
        "# model = LanguageModel(tokenizer.total_tokens)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "val_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "@tf.function\n",
        "def train_step(focus_word, context_word, label):\n",
        "    with tf.GradientTape() as tape:\n",
        "        output = model(focus_word, context_word, training=True)\n",
        "        loss = loss_fn(label, output)\n",
        "    \n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def val_step(focus_word, context_word, label):\n",
        "    output = model(focus_word, context_word, training=True)\n",
        "    loss = loss_fn(label, output)\n",
        "    val_loss(loss)\n",
        "\n",
        "\n",
        "# Main Training Loop\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss.reset_states()\n",
        "    val_loss.reset_states()\n",
        "\n",
        "    # Train Loop\n",
        "    train_loop = tqdm(total=train_dataset.cardinality().numpy(), position=0, leave=True)\n",
        "    for focus_word, context_word, label in train_dataset:\n",
        "        train_step(focus_word, context_word, label)\n",
        "        train_loop.set_description('Train - Epoch: {}, Loss: {:.4f}'.format(epoch, train_loss.result()))\n",
        "        train_loop.update(1)\n",
        "    train_loop.close()\n",
        "\n",
        "    # Validation Loop\n",
        "    val_loop = tqdm(total=val_dataset.cardinality().numpy(), position=0, leave=True)\n",
        "    for focus_word, context_word, label in val_dataset:\n",
        "        val_step(focus_word, context_word, label)\n",
        "        val_loop.set_description('Val   - Epoch: {}, Loss: {:.4f}'.format(epoch, val_loss.result()))\n",
        "        val_loop.update(1)\n",
        "    val_loop.close()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Epoch: 0, Loss: 0.5686: 100%|██████████| 598/598 [02:07<00:00,  4.69it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 1, Loss: 0.4995: 100%|██████████| 598/598 [02:11<00:00,  4.56it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 2, Loss: 0.4745: 100%|██████████| 598/598 [02:08<00:00,  4.65it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 3, Loss: 0.4583: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 4, Loss: 0.4465: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 5, Loss: 0.4376: 100%|██████████| 598/598 [02:12<00:00,  4.51it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 6, Loss: 0.4307: 100%|██████████| 598/598 [02:08<00:00,  4.66it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 7, Loss: 0.4253: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 8, Loss: 0.4210: 100%|██████████| 598/598 [02:08<00:00,  4.66it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 9, Loss: 0.4176: 100%|██████████| 598/598 [02:08<00:00,  4.65it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 10, Loss: 0.4147: 100%|██████████| 598/598 [02:12<00:00,  4.51it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 11, Loss: 0.4124: 100%|██████████| 598/598 [02:08<00:00,  4.64it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 12, Loss: 0.4105: 100%|██████████| 598/598 [02:09<00:00,  4.60it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 13, Loss: 0.4088: 100%|██████████| 598/598 [02:09<00:00,  4.61it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 14, Loss: 0.4074: 100%|██████████| 598/598 [02:13<00:00,  4.49it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 15, Loss: 0.4061: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 16, Loss: 0.4051: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 17, Loss: 0.4041: 100%|██████████| 598/598 [02:09<00:00,  4.61it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 18, Loss: 0.4032: 100%|██████████| 598/598 [02:11<00:00,  4.56it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 19, Loss: 0.4025: 100%|██████████| 598/598 [02:13<00:00,  4.48it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 20, Loss: 0.4018: 100%|██████████| 598/598 [02:08<00:00,  4.64it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 21, Loss: 0.4012: 100%|██████████| 598/598 [02:10<00:00,  4.57it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 22, Loss: 0.4006: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 23, Loss: 0.4001: 100%|██████████| 598/598 [02:11<00:00,  4.53it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 24, Loss: 0.3996: 100%|██████████| 598/598 [02:09<00:00,  4.64it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 25, Loss: 0.3992: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 26, Loss: 0.3988: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 27, Loss: 0.3984: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 28, Loss: 0.3980: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 29, Loss: 0.3977: 100%|██████████| 598/598 [02:11<00:00,  4.53it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 30, Loss: 0.3974: 100%|██████████| 598/598 [02:10<00:00,  4.60it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 31, Loss: 0.3971: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 32, Loss: 0.3968: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 33, Loss: 0.3965: 100%|██████████| 598/598 [02:13<00:00,  4.48it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 34, Loss: 0.3963: 100%|██████████| 598/598 [02:08<00:00,  4.64it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 35, Loss: 0.3960: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 36, Loss: 0.3958: 100%|██████████| 598/598 [02:08<00:00,  4.66it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 37, Loss: 0.3956: 100%|██████████| 598/598 [02:09<00:00,  4.63it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 38, Loss: 0.3954: 100%|██████████| 598/598 [02:12<00:00,  4.50it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 39, Loss: 0.3952: 100%|██████████| 598/598 [02:10<00:00,  4.59it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 40, Loss: 0.3950: 100%|██████████| 598/598 [02:09<00:00,  4.60it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 41, Loss: 0.3948: 100%|██████████| 598/598 [02:09<00:00,  4.62it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 42, Loss: 0.3947: 100%|██████████| 598/598 [02:12<00:00,  4.51it/s]\n",
            "0it [00:05, ?it/s]\n",
            "Train - Epoch: 43, Loss: 0.3947:  32%|███▏      | 191/598 [00:41<01:27,  4.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c1b6de837cc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfocus_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfocus_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train - Epoch: {}, Loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1KDZK0Qb01X",
        "outputId": "04098112-f05d-4e8f-e83d-2fcb3e916476",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tf.keras.layers.Embedding(tokenizer.total_tokens, output_dim=512, input_length=2)(tf.constant([1255, 28966], dtype=tf.int32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[ 0.01976549,  0.04826181, -0.01614144, ..., -0.0477993 ,\n",
              "         0.00367948, -0.00162051],\n",
              "       [ 0.02253098,  0.03827525, -0.03255246, ...,  0.00961969,\n",
              "         0.04651088, -0.018433  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fzbKSmWXszM",
        "outputId": "a34dc8cf-cf7f-46bc-b11b-2e9277fce8b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.texts_to_sequences('jean mary')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20871, 29765]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iI_FTWGZ9G0"
      },
      "source": [
        "embedding_weights = model.embedding.get_weights()\n",
        "\n",
        "np.save('french_embedding_weights', embedding_weights)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPSTKyiWbT4A",
        "outputId": "d794a2af-52d9-4c69-ac87-11d30bb4202e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedding_weights_reloaded = np.load('french_embedding_weights.npy')\n",
        "\n",
        "new_embedding = tf.keras.layers.Embedding(tokenizer.total_tokens, 128, mask_zero=True, weights=embedding_weights_reloaded)\n",
        "\n",
        "new_embedding(tf.constant([1], dtype=tf.int32))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
              "array([[-0.01672193, -0.0382713 ,  0.02569241,  0.01471088, -0.00602205,\n",
              "         0.00716635, -0.01385874, -0.00165684, -0.04858153, -0.00328467,\n",
              "        -0.02989974, -0.0123291 , -0.02526921,  0.01982469,  0.01533956,\n",
              "         0.00945605,  0.03954988,  0.02423957, -0.02601607,  0.03208761,\n",
              "        -0.02730244,  0.0046377 ,  0.03404119, -0.03013763, -0.00308994,\n",
              "         0.04550319, -0.03893144, -0.00115867, -0.00341796, -0.01423977,\n",
              "        -0.04445725,  0.03110829, -0.04505843,  0.03882005, -0.03786334,\n",
              "        -0.01588675, -0.02065988, -0.03719121, -0.02261881, -0.00511817,\n",
              "         0.00354328, -0.04019163,  0.00448092, -0.02389852, -0.04665628,\n",
              "         0.04998109,  0.0340411 , -0.00846102, -0.00019098,  0.01156087,\n",
              "        -0.00913759,  0.00788335,  0.01099713, -0.01221796, -0.02866399,\n",
              "         0.03300605, -0.01870582,  0.004679  , -0.04505099,  0.01431693,\n",
              "         0.0286878 , -0.01841231,  0.04636187, -0.03951782,  0.01553818,\n",
              "        -0.03613427,  0.00332525, -0.03162602,  0.04629518,  0.02290061,\n",
              "         0.02489574, -0.02659001,  0.04769137,  0.00590479,  0.00794964,\n",
              "         0.02424035,  0.03198553,  0.03082976, -0.0107717 , -0.01435458,\n",
              "         0.009048  ,  0.00885691, -0.04222568, -0.00706311, -0.00508766,\n",
              "        -0.0388057 , -0.00626396,  0.02372203,  0.03284078, -0.02395151,\n",
              "         0.01980405,  0.02825514, -0.04991619,  0.01454649,  0.02332309,\n",
              "         0.01643139, -0.04304396, -0.0189719 ,  0.00761028,  0.04306421,\n",
              "         0.04101587,  0.02858362,  0.01206251,  0.01284517, -0.04657112,\n",
              "         0.0456463 , -0.02340975, -0.02709617,  0.02612637,  0.01396544,\n",
              "         0.04612347,  0.03303761,  0.01884706, -0.02065669, -0.04520807,\n",
              "        -0.00445253,  0.02292125, -0.04206952,  0.02815657,  0.00589423,\n",
              "        -0.04406229, -0.04987979,  0.0373919 ,  0.02170608,  0.04012236,\n",
              "         0.01880382, -0.02071077, -0.01169119]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRhWG3MeYlec",
        "outputId": "026c3c2b-ecbb-4644-89e8-44da70cae3f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss_fn([0], [0.1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.10536041>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_AQAkRRYFAT",
        "outputId": "2ce14b2a-7672-489e-f4cb-272460595619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(tf.constant([20871]), tf.constant([29765]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9957212]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMUjFfBaXjlU"
      },
      "source": [
        "tokenizer.texts_to_sequences([['Jean', 'Mary']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cv57ZZZXcv8"
      },
      "source": [
        "model(tokenizer.t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9DDy_cxcpi_",
        "outputId": "6776d777-2eaa-49c0-8177-f5340be446f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrL-2us5czC0"
      },
      "source": [
        "!cp french_embedding_weights.npy 'drive/My Drive/'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHdK9tPEskSd"
      },
      "source": [
        "### Character-Level Results\n",
        "\n",
        "Observe the results by generating text one character at a time.\n",
        "\n",
        "Run this code block if you chose the character-level dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE3FD01sfk4G",
        "outputId": "053157e4-c60e-4582-de28-e02cffa4178d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input = tf.constant([197])\n",
        "string_output = ''\n",
        "k = 2\n",
        "model.gru.reset_states()\n",
        "for _ in range(200):  # Max number of iterations\n",
        "    output = model(input)\n",
        "    char_idx = np.random.choice(tf.math.top_k(output, k=k).indices.numpy()[0])\n",
        "    if char_idx == 198:\n",
        "        break\n",
        "    string_output += mapper.idx_to_char(char_idx)\n",
        "    input = tf.constant([char_idx])\n",
        "\n",
        "print(string_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c'une dux-sevatier à civellie he Mremen de querarancisquin maite de Stint née àa Marine mandien Avels neur en sept ans, tors apons du secour en,, dé laven apés neufante du sorre et de la cinq hons som\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKRq7fbMBcVd"
      },
      "source": [
        "### Word-Level Results\n",
        "\n",
        "Observe the results by generating text one word at a time.\n",
        "\n",
        "Run this code block if you chose the word-level dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoF4jM5jEnIb",
        "outputId": "4c97889b-130c-4cf4-dde6-9edf920450c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input = tf.constant([1042])  # Start token\n",
        "k = 30\n",
        "model.gru.reset_states()\n",
        "sequences = []\n",
        "for _ in range(15):\n",
        "    output = model(input)\n",
        "    char_idx = np.random.choice(tf.math.top_k(output, k=k).indices.numpy()[0])\n",
        "    if char_idx == 1043:\n",
        "        break\n",
        "    sequences.append(char_idx)\n",
        "\n",
        "print(tokenizer.sequences_to_texts([sequences]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['huit la mil en deux deux à Francois trente quatre la en deux à cinq']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}