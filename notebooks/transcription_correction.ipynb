{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transcription-correction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoMUTFDP4hv3qg8d66Jfyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BYU-Handwriting-Lab/GettingStarted/blob/master/notebooks/transcription_correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaFc3NgN8cmC",
        "colab_type": "text"
      },
      "source": [
        "# Language Model Text Error Correction\n",
        "\n",
        "This notebook contains code that corrects the output of a handwriting\n",
        "recognition model using techniques from neural machine translation. We\n",
        "implement a basic encoder/decoder architecture with a transformer to\n",
        "correct the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C3o3IxcH1lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRipraCUHv5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Python\n",
        "import os\n",
        "\n",
        "# Data Structures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Image/Plotting\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Debugging\n",
        "from tqdm import tqdm\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode='Verbose', color_scheme='LightBg', tb_offset=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPtxnInShAdc",
        "colab_type": "text"
      },
      "source": [
        "Download the Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5mNX5YmZO68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1w0sumZm2YPxgMAsz9utAm9t2HriIe-JL' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1w0sumZm2YPxgMAsz9utAm9t2HriIe-JL\" -O error.csv && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw3sn5UnK1CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ID: 1liD_6fJvmRaQW4SjB3FPtfgd1vHrwxMN\n",
        "!wget -q --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1liD_6fJvmRaQW4SjB3FPtfgd1vHrwxMN' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1liD_6fJvmRaQW4SjB3FPtfgd1vHrwxMN\" -O rimes.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q rimes.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKKhDn5i_etf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0klYJN4cZ2ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CHAR_SET = {'char_to_idx': {'Ĵ': '318', '¬': '1', 'Õ': '2', 'Y': '3', 'Į': '4', 'ø': '5', 'Ÿ': '6', ',': '7', '«': '8', 'ĳ': '9', 'e': '10', 'Ô': '11', 'U': '12', '[': '13', 'j': '14', 'Ũ': '15', '3': '16', 'o': '17', 'ï': '18', 'd': '19', 'x': '20', 'ċ': '21', 'Ü': '22', 'ı': '23', 'Ð': '24', 'Ď': '25', 'Ŋ': '26', '2': '27', '®': '28', '9': '29', 'ß': '30', 'ľ': '31', '/': '32', 'V': '33', '½': '34', 'û': '35', 'h': '36', 'ě': '37', 'r': '38', 'm': '39', '¥': '40', 'g': '41', 'ĺ': '42', 'B': '43', 'Ė': '44', 'Ř': '45', 'Ĺ': '46', 'Ò': '47', 'ĥ': '48', 'À': '49', '{': '50', 'Ž': '51', 'ã': '52', ':': '53', 'Ì': '54', 'Ī': '55', 'Ķ': '56', 'ń': '57', 'õ': '58', 'Å': '59', 'G': '60', 'È': '61', 'ſ': '62', 'Ą': '63', '5': '64', 'ë': '65', 'Ō': '66', 'ŋ': '67', 'ţ': '68', 'Ħ': '69', 'Q': '70', 'č': '71', 'Ŀ': '72', '=': '73', 'Ĉ': '74', 'Ş': '75', 'Ū': '76', 'ħ': '77', 'ŗ': '78', 'É': '79', '%': '80', 'ť': '81', 'æ': '82', '±': '83', '?': '84', 'D': '85', '»': '86', 'ż': '87', 'ć': '88', '<': '89', '|': '90', 'C': '91', 'Ġ': '92', '´': '93', 'ŏ': '94', '.': '95', '$': '96', 'ü': '97', '+': '98', 'ġ': '99', 'Ï': '100', 'ŕ': '101', 'Ă': '102', 'i': '103', 'Ý': '104', '\"': '105', 'w': '106', 'Ù': '107', 'Ŝ': '108', 'Đ': '109', 'Ä': '110', 'ì': '111', '`': '112', 'ű': '113', '\\xad': '114', 'ģ': '115', 'î': '116', '7': '117', 'Ö': '118', 'İ': '119', 'ĵ': '120', 'Z': '121', '¶': '122', 'Ņ': '123', '¨': '124', '4': '125', 'R': '126', ']': '127', '^': '128', 'F': '129', 'ļ': '130', 'ğ': '131', 'k': '132', 'ī': '133', 'é': '134', 'ŉ': '135', 'Ń': '136', 'Ľ': '137', '!': '138', 'ù': '139', 'Ĳ': '140', 'S': '141', 'E': '142', 'â': '143', ')': '144', '·': '145', '¾': '146', 'Þ': '147', 'Ł': '148', 'ř': '149', 'Ļ': '150', 'Ê': '151', 'ä': '152', 'n': '153', 'œ': '154', '(': '155', 'ĕ': '156', '§': '157', 'ê': '158', '°': '159', 'ý': '160', '@': '161', 'Ź': '162', '-': '163', 'Ţ': '164', 'ũ': '165', 'ė': '166', '0': '167', 'Ĩ': '168', 'ş': '169', 'š': '170', 'ō': '171', 'ą': '172', 'H': '173', 'ų': '174', 'O': '175', 'ŭ': '176', ' ': '177', 'ñ': '178', 'ś': '179', 'b': '180', '¦': '181', 'Ú': '182', 'Œ': '183', 'ª': '184', 'ĩ': '185', 'W': '186', 'M': '187', 'ă': '188', 'ö': '189', 'ž': '190', 'ò': '191', 'µ': '192', 'f': '193', 'ň': '194', 'þ': '195', '1': '196', 'Ç': '197', 'Ć': '198', '¹': '199', 'Ŗ': '200', 'á': '201', 'c': '202', '>': '203', '8': '204', 'ł': '205', 'Š': '206', 'ő': '207', 'Ģ': '208', 'ŷ': '209', 'Ĕ': '210', 'Ś': '211', 'ŝ': '212', 'ź': '213', 'Â': '214', 'ĭ': '215', '³': '216', 'Ċ': '217', 'Ã': '218', 'į': '219', 'l': '220', 'Û': '221', 'Ĭ': '222', 'Ŧ': '223', 'Ż': '224', 'K': '225', 'N': '226', '¡': '227', '_': '228', 'å': '229', '£': '230', 'ū': '231', 'Ų': '232', '×': '233', 'Ā': '234', 'u': '235', 'ů': '236', 'Ě': '237', '*': '238', 'v': '239', 'T': '240', 'Ŕ': '241', 'ē': '242', 'A': '243', 'X': '244', '¼': '245', 'q': '246', '¤': '247', 's': '248', 'Ű': '249', 't': '250', 'Ŷ': '251', 'Č': '252', 'ĝ': '253', '\\\\': '254', 'Ů': '255', '#': '256', \"'\": '257', 'Á': '258', '¿': '259', '}': '260', 'y': '261', 'Ē': '262', 'Ŭ': '263', 'Ë': '264', '~': '265', 'Ę': '266', 'Ŵ': '267', 'Æ': '268', 'ð': '269', 'º': '270', 'Ó': '271', 'ā': '272', 'ô': '273', 'J': '274', 'ÿ': '275', 'ó': '276', 'Ĝ': '277', '&': '278', 'P': '279', '©': '280', 'Ğ': '281', 'è': '282', 'ę': '283', 'ĸ': '284', '²': '285', 'Ĥ': '286', '¢': '287', 'ŵ': '288', 'Î': '289', 'đ': '290', 'Í': '291', 'a': '292', ';': '293', 'à': '294', '¯': '295', '¸': '296', 'ņ': '297', 'L': '298', 'Ő': '299', 'ķ': '300', 'p': '301', 'Ŏ': '302', 'í': '303', 'ŧ': '304', 'ç': '305', 'Ť': '306', 'ŀ': '307', 'z': '308', 'ď': '309', 'Ň': '310', '6': '311', 'I': '312', '÷': '313', 'ú': '314', 'Ø': '315', 'Ñ': '316', 'ĉ': '317'},\n",
        "            'idx_to_char': {'318': 'Ĵ', '1': '¬', '2': 'Õ', '3': 'Y', '4': 'Į', '5': 'ø', '6': 'Ÿ', '7': ',', '8': '«', '9': 'ĳ', '10': 'e', '11': 'Ô', '12': 'U', '13': '[', '14': 'j', '15': 'Ũ', '16': '3', '17': 'o', '18': 'ï', '19': 'd', '20': 'x', '21': 'ċ', '22': 'Ü', '23': 'ı', '24': 'Ð', '25': 'Ď', '26': 'Ŋ', '27': '2', '28': '®', '29': '9', '30': 'ß', '31': 'ľ', '32': '/', '33': 'V', '34': '½', '35': 'û', '36': 'h', '37': 'ě', '38': 'r', '39': 'm', '40': '¥', '41': 'g', '42': 'ĺ', '43': 'B', '44': 'Ė', '45': 'Ř', '46': 'Ĺ', '47': 'Ò', '48': 'ĥ', '49': 'À', '50': '{', '51': 'Ž', '52': 'ã', '53': ':', '54': 'Ì', '55': 'Ī', '56': 'Ķ', '57': 'ń', '58': 'õ', '59': 'Å', '60': 'G', '61': 'È', '62': 'ſ', '63': 'Ą', '64': '5', '65': 'ë', '66': 'Ō', '67': 'ŋ', '68': 'ţ', '69': 'Ħ', '70': 'Q', '71': 'č', '72': 'Ŀ', '73': '=', '74': 'Ĉ', '75': 'Ş', '76': 'Ū', '77': 'ħ', '78': 'ŗ', '79': 'É', '80': '%', '81': 'ť', '82': 'æ', '83': '±', '84': '?', '85': 'D', '86': '»', '87': 'ż', '88': 'ć', '89': '<', '90': '|', '91': 'C', '92': 'Ġ', '93': '´', '94': 'ŏ', '95': '.', '96': '$', '97': 'ü', '98': '+', '99': 'ġ', '100': 'Ï', '101': 'ŕ', '102': 'Ă', '103': 'i', '104': 'Ý', '105': '\"', '106': 'w', '107': 'Ù', '108': 'Ŝ', '109': 'Đ', '110': 'Ä', '111': 'ì', '112': '`', '113': 'ű', '114': '\\xad', '115': 'ģ', '116': 'î', '117': '7', '118': 'Ö', '119': 'İ', '120': 'ĵ', '121': 'Z', '122': '¶', '123': 'Ņ', '124': '¨', '125': '4', '126': 'R', '127': ']', '128': '^', '129': 'F', '130': 'ļ', '131': 'ğ', '132': 'k', '133': 'ī', '134': 'é', '135': 'ŉ', '136': 'Ń', '137': 'Ľ', '138': '!', '139': 'ù', '140': 'Ĳ', '141': 'S', '142': 'E', '143': 'â', '144': ')', '145': '·', '146': '¾', '147': 'Þ', '148': 'Ł', '149': 'ř', '150': 'Ļ', '151': 'Ê', '152': 'ä', '153': 'n', '154': 'œ', '155': '(', '156': 'ĕ', '157': '§', '158': 'ê', '159': '°', '160': 'ý', '161': '@', '162': 'Ź', '163': '-', '164': 'Ţ', '165': 'ũ', '166': 'ė', '167': '0', '168': 'Ĩ', '169': 'ş', '170': 'š', '171': 'ō', '172': 'ą', '173': 'H', '174': 'ų', '175': 'O', '176': 'ŭ', '177': ' ', '178': 'ñ', '179': 'ś', '180': 'b', '181': '¦', '182': 'Ú', '183': 'Œ', '184': 'ª', '185': 'ĩ', '186': 'W', '187': 'M', '188': 'ă', '189': 'ö', '190': 'ž', '191': 'ò', '192': 'µ', '193': 'f', '194': 'ň', '195': 'þ', '196': '1', '197': 'Ç', '198': 'Ć', '199': '¹', '200': 'Ŗ', '201': 'á', '202': 'c', '203': '>', '204': '8', '205': 'ł', '206': 'Š', '207': 'ő', '208': 'Ģ', '209': 'ŷ', '210': 'Ĕ', '211': 'Ś', '212': 'ŝ', '213': 'ź', '214': 'Â', '215': 'ĭ', '216': '³', '217': 'Ċ', '218': 'Ã', '219': 'į', '220': 'l', '221': 'Û', '222': 'Ĭ', '223': 'Ŧ', '224': 'Ż', '225': 'K', '226': 'N', '227': '¡', '228': '_', '229': 'å', '230': '£', '231': 'ū', '232': 'Ų', '233': '×', '234': 'Ā', '235': 'u', '236': 'ů', '237': 'Ě', '238': '*', '239': 'v', '240': 'T', '241': 'Ŕ', '242': 'ē', '243': 'A', '244': 'X', '245': '¼', '246': 'q', '247': '¤', '248': 's', '249': 'Ű', '250': 't', '251': 'Ŷ', '252': 'Č', '253': 'ĝ', '254': '\\\\', '255': 'Ů', '256': '#', '257': \"'\", '258': 'Á', '259': '¿', '260': '}', '261': 'y', '262': 'Ē', '263': 'Ŭ', '264': 'Ë', '265': '~', '266': 'Ę', '267': 'Ŵ', '268': 'Æ', '269': 'ð', '270': 'º', '271': 'Ó', '272': 'ā', '273': 'ô', '274': 'J', '275': 'ÿ', '276': 'ó', '277': 'Ĝ', '278': '&', '279': 'P', '280': '©', '281': 'Ğ', '282': 'è', '283': 'ę', '284': 'ĸ', '285': '²', '286': 'Ĥ', '287': '¢', '288': 'ŵ', '289': 'Î', '290': 'đ', '291': 'Í', '292': 'a', '293': ';', '294': 'à', '295': '¯', '296': '¸', '297': 'ņ', '298': 'L', '299': 'Ő', '300': 'ķ', '301': 'p', '302': 'Ŏ', '303': 'í', '304': 'ŧ', '305': 'ç', '306': 'Ť', '307': 'ŀ', '308': 'z', '309': 'ď', '310': 'Ň', '311': '6', '312': 'I', '313': '÷', '314': 'ú', '315': 'Ø', '316': 'Ñ', '317': 'ĉ'}\n",
        "           }\n",
        "\n",
        "class CharsetMapper:\n",
        "  def __init__(self, max_sequence_size=128, start=319, end=320):\n",
        "    self.max_sequence_size = max_sequence_size\n",
        "    self.start = start\n",
        "    self.end = end\n",
        "\n",
        "  @staticmethod\n",
        "  def remove_duplicates(idxs):\n",
        "    new_idxs = []\n",
        "\n",
        "    for i in range(len(idxs)):\n",
        "        # Only append if the next character in the sequence is not\n",
        "        # identical to the current character. If we're at the end of\n",
        "        # the sequence, add it.\n",
        "      if i + 1 == len(idxs) or idxs[i] != idxs[i + 1]:\n",
        "        new_idxs.append(idxs[i])\n",
        "\n",
        "    return new_idxs\n",
        "\n",
        "  def idx_to_char(self, idx):\n",
        "    if idx in [self.start, self.end]:\n",
        "        return ''  # Return empty string for the blank character\n",
        "    else:\n",
        "      try:\n",
        "        return CHAR_SET['idx_to_char'][str(int(idx))]\n",
        "      except KeyError:\n",
        "        return ''\n",
        "\n",
        "  def char_to_idx(self, char):\n",
        "      return int(CHAR_SET['char_to_idx'][char])\n",
        "\n",
        "  def str_to_idxs(self, string):\n",
        "    idxs = [self.start]\n",
        "\n",
        "    for char in string:\n",
        "      try:\n",
        "        idxs.append(self.char_to_idx(char))\n",
        "      except:\n",
        "        continue\n",
        "    \n",
        "    idxs.append(self.end)\n",
        "\n",
        "    # Pad the array to the max sequence size\n",
        "    return idxs\n",
        "\n",
        "  def idxs_to_str(self, idxs, remove_duplicates=True):\n",
        "    string = ''\n",
        "\n",
        "    if remove_duplicates:\n",
        "      idxs = CharsetMapper.remove_duplicates(idxs)\n",
        "\n",
        "    for idx in idxs:\n",
        "      string += self.idx_to_char(idx)\n",
        "\n",
        "    return string\n",
        "\n",
        "  def str_to_idxs_batch(self, batch):\n",
        "    idxs = []\n",
        "\n",
        "    for string in batch:\n",
        "      idx = self.str_to_idxs(string)\n",
        "      idxs.append(idx)\n",
        "\n",
        "    return idxs\n",
        "\n",
        "  def idxs_to_str_batch(self, batch, remove_duplicates=True):\n",
        "    strings = []\n",
        "\n",
        "    for idxs in batch:\n",
        "      strings.append(self.idxs_to_str(idxs, remove_duplicates=remove_duplicates))\n",
        "\n",
        "    return strings\n",
        "\n",
        "  def get_vocab_size(self):\n",
        "    return len(CHAR_SET['char_to_idx']) + 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qw8qEWlZobt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ErrorSequence(tf.keras.utils.Sequence):\n",
        "  def __init__(self, path='/content/error.csv'):\n",
        "    self.df = pd.read_csv(path, header=None, sep='\\t', names=['original', 'error'])\n",
        "    self.charset_mapper = CharsetMapper()\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    x = self.charset_mapper.str_to_idxs(str(self.df['error'][index]))\n",
        "    x = tf.keras.preprocessing.sequence.pad_sequences([x], maxlen=128, padding='post')[0]\n",
        "    y = self.charset_mapper.str_to_idxs(str(self.df['original'][index]))\n",
        "    y = tf.keras.preprocessing.sequence.pad_sequences([y], maxlen=128, padding='post')[0]\n",
        "\n",
        "    return tf.constant(x, dtype=tf.int64), tf.constant(y, dtype=tf.int64)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.df)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH_7n2NhZycs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0058a525-1227-41ed-be35-8d6a36de174b"
      },
      "source": [
        "sequence = ErrorSequence()\n",
        "mapper = CharsetMapper()\n",
        "x, y = sequence[4]\n",
        "\n",
        "print('error idx:', x.numpy())\n",
        "print('error:', mapper.idxs_to_str(x.numpy()))\n",
        "print('corrected idx:', y.shape)\n",
        "print('corrected:', mapper.idxs_to_str(y.numpy()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error idx: [319 142 244 248 250  10 177 292 220 193 292  38  38 201 180 103  17   7\n",
            " 177 153  52 124  17 177  17 177  19  10 239  17  17 177 292  17 177  39\n",
            "  10 235 177 239  10 220  36  49 177 202  38  17 153 103 248 248 250 292\n",
            " 177  19  17 177 279 292 248 248 248  10 103  17 261 177 279 314 180 274\n",
            " 103 202  17  95 177 177  79   7 177 202  17  39  17 177 248  10 177  19\n",
            " 103 248 248  10 177 153  17 320   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0]\n",
            "error: EXste alfarábio, nã¨o o devo ao meu velhÀ cronista do Paseioy PúbJico. É, como se dise no\n",
            "corrected idx: (128,)\n",
            "corrected: Este alfarábio, não o devo ao meu velho cronista do Paseio Público. É, como se dise no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSrvjjFKZ4rj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tfrecord_from_sequence(sequence, tfrecord_path):\n",
        "    \"\"\"\n",
        "    Create a TfRecord dataset from a sequence\n",
        "\n",
        "    :param sequence: The Keras sequence to load dataasdfs of arbitrary format\n",
        "    :param tfrecord_path: Filepath and name for location of TfRecord dataset\n",
        "    \"\"\"\n",
        "    print('Started creating TFRecord Dataset...')\n",
        "\n",
        "    writer = tf.io.TFRecordWriter(tfrecord_path)\n",
        "\n",
        "    for index, (img, label) in enumerate(sequence):\n",
        "        feature = {'label': _bytes_feature(tf.io.serialize_tensor(label)),\n",
        "                   'image': _bytes_feature(tf.io.serialize_tensor(img))}\n",
        "\n",
        "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "        writer.write(example.SerializeToString())\n",
        "        if index % 1000 == 0:\n",
        "            print(str(index) + '/' + str(len(sequence)))\n",
        "\n",
        "    print(str(len(sequence)) + '/' + str(len(sequence)))\n",
        "\n",
        "    print('Finished: TFRecord created at', tfrecord_path)\n",
        "\n",
        "\n",
        "def read_tfrecord(single_record):\n",
        "    \"\"\"\n",
        "    Function to decode a TfRecord. Usually this function will be called within\n",
        "    a TfDataset map function. Note that out_types for image and label must be\n",
        "    tf.float32 and tf.int64 respectively.\n",
        "\n",
        "    :param single_record: A single TfRecord\n",
        "    :return: A decoded image and label as tensors\n",
        "    \"\"\"\n",
        "    feature_description = {\n",
        "        'label': tf.io.FixedLenFeature((), tf.string),\n",
        "        'image': tf.io.FixedLenFeature((), tf.string)\n",
        "    }\n",
        "\n",
        "    single_record = tf.io.parse_single_example(single_record, feature_description)\n",
        "\n",
        "    image = tf.io.parse_tensor(single_record['image'], out_type=tf.int64)\n",
        "    label = tf.io.parse_tensor(single_record['label'], out_type=tf.int64)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()  # BytesList won't unpack a string from an EagerTensor.\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm1cjCPPZ8Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_tfrecord_from_sequence(ErrorSequence(), 'error.tfrecord')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCawjgbxRv5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Train:\n",
        "  def __init__(self):\n",
        "    # Training\n",
        "    self.EPOCHS = 10\n",
        "    self.BATCH_SIZE = 128\n",
        "\n",
        "    dataset_size = 100_000\n",
        "    self.train_size = int(.8 * dataset_size)\n",
        "    self.val_size = dataset_size - self.train_size\n",
        "    self.dataset = tf.data.TFRecordDataset('error.tfrecord').map(read_tfrecord).shuffle(dataset_size)\n",
        "    self.train_dataset = self.dataset.take(self.train_size).batch(self.BATCH_SIZE, drop_remainder=True)\n",
        "    self.val_dataset = self.dataset.skip(self.val_size).take(self.val_size).batch(self.BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "    # dataset = tf.data.experimental.CsvDataset('./labels.csv', [tf.string], field_delim='\\t', use_quote_delim=False, select_cols=[1])\\\n",
        "                                              # .map(lambda src: tf.py_function(encode, [src], Tout=[tf.int32, tf.int32]))\\\n",
        "                                              # .batch(self.BATCH_SIZE)\n",
        "    # self.dataset = tf.data.Dataset.from_tensor_slices(tf.ragged.constant(instances, dtype=tf.int32)).map(lambda sentence: tf.py_function(encode, [sentence], Tout=[tf.int32, tf.int32])).batch(self.BATCH_SIZE)                        \n",
        "\n",
        "    self.encoder = Encoder(321, 256, 256, self.BATCH_SIZE)\n",
        "    self.decoder = Decoder(321, 256, 256, self.BATCH_SIZE)\n",
        "\n",
        "    self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    self.loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "    self.train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    self.val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "  \n",
        "  def train_step(self, src, trg, enc_hidden):\n",
        "    loss = 0.0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      enc_output, enc_hidden = self.encoder(src, enc_hidden)\n",
        "      dec_hidden = enc_hidden\n",
        "      dec_input = tf.expand_dims([319] * self.BATCH_SIZE, 1)\n",
        "\n",
        "      # Teacher Forcing - feeding the target as the next input\n",
        "      for t in range(1, trg.shape[1]):\n",
        "        # Passing enc_output to the decoder\n",
        "        predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "        loss += self.loss_function(trg[:, t], predictions)\n",
        "        dec_input = tf.expand_dims(trg[:, t], 1)\n",
        "      \n",
        "      batch_loss = loss / int(trg.shape[1])\n",
        "      variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "      gradients = tape.gradient(loss, variables)\n",
        "\n",
        "      self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "    self.train_loss(batch_loss)\n",
        "\n",
        "  def val_step(self, src, trg, enc_hidden):\n",
        "    loss = 0.0\n",
        "    enc_output, enc_hidden = self.encoder(src, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([319] * self.BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher Forcing - feeding the target as the next input\n",
        "    for t in range(1, trg.shape[1]):\n",
        "      # Passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += self.loss_function(trg[:, t], predictions)\n",
        "      dec_input = tf.expand_dims(trg[:, t], 1)\n",
        "    \n",
        "    batch_loss = loss / int(trg.shape[1])\n",
        "    self.val_loss(batch_loss)\n",
        "\n",
        "  def loss_function(self, real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = self.loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "  \n",
        "  def __call__(self):\n",
        "    for epoch in range(self.EPOCHS):\n",
        "      self.train_loss.reset_states()\n",
        "      enc_hidden = self.encoder.initialize_hidden_state()\n",
        "\n",
        "      train_loop = tqdm(total=self.train_size//self.BATCH_SIZE, position=0, leave=True)\n",
        "      for src, trg in self.train_dataset:\n",
        "        self.train_step(src, trg, enc_hidden)\n",
        "        train_loop.set_description('Train - Epoch: {}, Loss: {:.4f}'.format(epoch, self.train_loss.result()))\n",
        "        train_loop.update(1)\n",
        "      train_loop.close()\n",
        "\n",
        "      self.val_loss.reset_states()\n",
        "      enc_hidden = self.encoder.initialize_hidden_state()\n",
        "\n",
        "      val_loop = tqdm(total=self.val_size//self.BATCH_SIZE, position=0, leave=True)\n",
        "      for src, trg, in self.val_dataset:\n",
        "        self.val_step(src, trg, enc_hidden)\n",
        "        val_loop.set_description('Val   - Epoch: {}, Loss: {:.4f}'.format(epoch, self.val_loss.result()))\n",
        "        val_loop.update(1)\n",
        "      val_loop.close()"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-aIEAbaSbZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "53019a19-5039-44a1-a2db-3480ed834bd2"
      },
      "source": [
        "train = Train()\n",
        "train()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Epoch: 0, Loss: 1.2166: 100%|██████████| 625/625 [17:06<00:00,  1.64s/it]\n",
            "Val   - Epoch: 0, Loss: 1.0785: 100%|██████████| 156/156 [02:34<00:00,  1.01it/s]\n",
            "Train - Epoch: 1, Loss: 1.0097: 100%|██████████| 625/625 [17:08<00:00,  1.65s/it]\n",
            "Val   - Epoch: 1, Loss: 0.9504: 100%|██████████| 156/156 [02:35<00:00,  1.00it/s]\n",
            "Train - Epoch: 2, Loss: 0.5712: 100%|██████████| 625/625 [16:48<00:00,  1.61s/it]\n",
            "Val   - Epoch: 2, Loss: 0.2548: 100%|██████████| 156/156 [02:30<00:00,  1.04it/s]\n",
            "Train - Epoch: 3, Loss: 0.2460: 100%|██████████| 625/625 [16:36<00:00,  1.59s/it]\n",
            "Val   - Epoch: 3, Loss: 0.2709: 100%|██████████| 156/156 [02:30<00:00,  1.04it/s]\n",
            "Train - Epoch: 4, Loss: 0.2083: 100%|██████████| 625/625 [16:35<00:00,  1.59s/it]\n",
            "Val   - Epoch: 4, Loss: 0.1650: 100%|██████████| 156/156 [02:30<00:00,  1.04it/s]\n",
            "Train - Epoch: 5, Loss: 0.2517: 100%|██████████| 625/625 [16:59<00:00,  1.63s/it]\n",
            "Val   - Epoch: 5, Loss: 0.1982: 100%|██████████| 156/156 [02:37<00:00,  1.01s/it]\n",
            "Train - Epoch: 6, Loss: 0.2285: 100%|██████████| 625/625 [17:11<00:00,  1.65s/it]\n",
            "Val   - Epoch: 6, Loss: 0.1960: 100%|██████████| 156/156 [02:32<00:00,  1.02it/s]\n",
            "Train - Epoch: 7, Loss: 0.1823: 100%|██████████| 625/625 [17:09<00:00,  1.65s/it]\n",
            "Val   - Epoch: 7, Loss: 0.1602:  44%|████▍     | 69/156 [01:10<01:24,  1.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  11168\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Transpose\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11169\u001b[0;31m         tld.op_callbacks, x, perm)\n\u001b[0m\u001b[1;32m  11170\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-6a965af9c074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-103-cb3b49a35325>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0mval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Val   - Epoch: {}, Loss: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-cb3b49a35325>\u001b[0m in \u001b[0;36mval_step\u001b[0;34m(self, src, trg, enc_hidden)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m       \u001b[0;31m# Passing enc_output to the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m       \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-916cb0447702>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# passing the concatenated vector to the GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# output shape == (batch_size * 1, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0;32m--> 438\u001b[0;31m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# Under eager context, check the device placement and prefer the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnormal_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgpu_gru\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0mlast_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtime_major\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[1;32m   2120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2122\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  11172\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11173\u001b[0m         return transpose_eager_fallback(\n\u001b[0;32m> 11174\u001b[0;31m             x, perm, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m  11175\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11176\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[0;34m(x, perm, name, ctx)\u001b[0m\n\u001b[1;32m  11195\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranspose_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11196\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11197\u001b[0;31m   \u001b[0m_attr_Tperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11198\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11199\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tperm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    261\u001b[0m       ret.append(\n\u001b[1;32m    262\u001b[0m           ops.convert_to_tensor(\n\u001b[0;32m--> 263\u001b[0;31m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0mpreferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversion_func\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;31m# If dtype is None but preferred_dtype is not None, we try to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[0;31m# cast to preferred_dtype first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsnLGv2_TAVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((128, 128))\n",
        "\n",
        "  mapper = CharsetMapper()\n",
        "  inputs = mapper.str_to_idxs(sentence)\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=128,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, 256))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([319], 0)\n",
        "\n",
        "  for t in range(128):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += mapper.idx_to_char(predicted_id)\n",
        "\n",
        "    if predicted_id == 320:\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTVA-jkc2rN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvLYwXf220yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(sentence, target):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "  print('Target translation: {}'.format(target))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpT80VDu6yKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JjMH6SofbGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "022967c7-0b6a-4e4b-efbc-0a7139c89166"
      },
      "source": [
        "!tail error.csv"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "um do outro, ofegantes de canseira, mas remidos com a paga. Unem-se,\tum0x ;outro, ofegantes de canstia, mas remidoos com a paga. Unem-se,\r\n",
            "entrelaçam os braços, e regressam palpitando da inconsciência para a consciência.\tentrelçam os braços,, e regrressam palpitandüo da inconsciência para a consciência.\r\n",
            "\"\"\"Quem é esta que sobe do deserto, firmada sobre o seu amado?\"\", pergunta Sílvio,\"\t\"\"\"Quem é esta que sobex do deoserto, firmada sobre o ≠seu amado?\"\", pe4guunt Sílvio,\"\r\n",
            "\"como no Cântico; e ela, com a mesma lábia erudita, responde-lhe que \"\"é o selo do\"\t\"como no Cântico; e elάa, com a mmesma  lábia eruditaá resonde-lhe que \"\"é o selo do\"\r\n",
            "\"seu coração\"\", e que \"\"o amor é tão valente como a própria morte\"\".\"\t\"seuucoração\"\"‒ e que \"\"o amor é tão valente como a própria morte\"\"J\"\r\n",
            "Nisto, o cônego estremece. O rosto ilumina-se-lhe. A pena, cheia de comoção e\tNisto,o cônego Üessstremece. OO rosto ilumina-se-lh⅗e. A pena, heîia de comooção e\r\n",
            "respeito, completa o substantivo com o adjetivo. Sílvia caminhará agora ao pé de\trespeito, completao substgantivo co  o adjetivo. 9ílvia camènhaáá agora Èo pé de\r\n",
            "Sílvio, no sermão que o cônego vai pregar um dia destes, e irão juntinhos ao\tSívio, no sermão que o cônego vai pregar um d∫ia destes, ee irão juntinhos aao\r\n",
            "prelo, se ele coligir os seus escritos, o que não se sabe.\tprelo, se æle coligir os seuss escritos,, o quee não sesabe.\r\n",
            "FIM\tFIM\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1H32yrQ2yWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "d439661f-3eb9-400c-9480-55f986c93c5e"
      },
      "source": [
        "encoder = train.encoder\n",
        "decoder = train.decoder\n",
        "\n",
        "translate('entrelçam os braços,, e regrressam palpitandüo da inconsciência para a consciência.', 'entrelaçam os braços, e regressam palpitando da inconsciência para a consciência.')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: entrelçam os braços,, e regrressam palpitandüo da inconsciência para a consciência.\n",
            "Predicted translation: entrelçam os braços, e regrressam palpitando da inconsciência para a consciência para a consciência para a consciência para a co\n",
            "Target translation: entrelaçam os braços, e regressam palpitando da inconsciência para a consciência.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}