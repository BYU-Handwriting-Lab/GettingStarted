{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HWRActiveTransferLearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+lEJRU1VaHtG+ZHZ7fUkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BYU-Handwriting-Lab/GettingStarted/blob/master/notebooks/HWRActiveTransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCYwlAtU1xbC"
      },
      "source": [
        "# Active Transfer Learning for Handwriting Recognition\n",
        "\n",
        "This notebook contains code to combine active and transfer learning into a\n",
        "cohesive framework. The hope is to allow for new handwriting datasets to be\n",
        "fitted quickly.\n",
        "\n",
        "In this notebook, we will start the process of fitting the Washington dataset\n",
        "when our list of pre-trained models were trained on the IAM, Rimes, and Bentham\n",
        "datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqyKe20vLq4Z"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "First, let's import our dependencies such as Tensorflow, numpy, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5vaA6qQ1xFj"
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as kl\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqeIC-ZOMWYq"
      },
      "source": [
        "## Load the data\n",
        "\n",
        "Here are a few functions to help us load our data into a format compatible with\n",
        "Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxBcOmKjSzxE"
      },
      "source": [
        "# The default list of characters used in the recognition model\n",
        "DEFAULT_CHARS = ' !\"#$%&\\'()*+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|~£§¨«¬\\xad' \\\n",
        "                '°²´·º»¼½¾ÀÂÄÇÈÉÊÔÖÜßàáâäæçèéêëìîïñòóôöøùúûüÿłŒœΓΖΤάήαδεηικλμνξοπρτυχψωόώІ‒–—†‡‰‹›₂₤℔⅓⅔⅕⅖⅗⅘⅙⅚⅛∆∇∫≠□♀♂✓ｆ’í‘\\\\♪'\n",
        "# The default list of non-punctuation characters needed for the word beam search decoding algorithm\n",
        "DEFAULT_NON_PUNCTUATION = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzÀÂÄÇÈÉÊÔÖÜßàáâäæçèéêëìîïñòóôöøùúûüÿ' \\\n",
        "                          'łŒœΓΖΤάήαδεηικλμνξοπρτυχψωόώІ'\n",
        "# The default list of punctuation characters needed for hte word beam search decoding algorithm\n",
        "DEFAULT_PUNCTUATION = ' !\"#$%&\\'()*+,-./0123456789:;=?[]_`|~£§¨«¬°²´·º»¼½¾‒–—†‡‰‹›₂₤℔⅓⅔⅕⅖⅗⅘⅙⅚⅛∆∇∫≠□♀♂✓'\n",
        "\n",
        "\n",
        "def str_charset_to_lists(charset):\n",
        "    \"\"\"\n",
        "    Turns string containing all desired characters into list of chars and indices. This is required for mapping\n",
        "    between integer and char representations for use in the recognition model.\n",
        "\n",
        "    :param charset: charset as string of chars to be represented in model.\n",
        "    \"\"\"\n",
        "    chars = list(charset)\n",
        "    indices = list(range(1, len(chars) + 1))\n",
        "    return chars, indices\n",
        "\n",
        "\n",
        "def get_char2idx(charset):\n",
        "    \"\"\"\n",
        "    A tensorflow lookup table is created and returned which allows us to encode word transcriptions on the fly\n",
        "    in the tf.data api. A standard python dictionary won't work when tensorflow is running in graph mode. This\n",
        "    function will return a lookup table to convert between chars and indices.\n",
        "\n",
        "    :param charset: string containing all desired characters to be represented\n",
        "    :return: A tensorflow lookup table to convert characters to integers\n",
        "    \"\"\"\n",
        "    chars, indices = str_charset_to_lists(charset)\n",
        "\n",
        "    char2idx = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(\n",
        "            keys=tf.constant(chars, dtype=tf.string),\n",
        "            values=tf.constant(indices, dtype=tf.int32),\n",
        "            key_dtype=tf.string,\n",
        "            value_dtype=tf.int32\n",
        "        ),\n",
        "        default_value=0,\n",
        "        name='char2idx_lookup'\n",
        "    )\n",
        "\n",
        "    return char2idx\n",
        "\n",
        "\n",
        "def get_idx2char(charset):\n",
        "    \"\"\"\n",
        "    A tensorflow lookup table is created and returned which allows us to encode word transcriptions on the fly\n",
        "    in the tf.data api. A standard python dictionary won't work when tensorflow is running in graph mode. This\n",
        "    function will return a lookup table to convert between indices and chars.\n",
        "\n",
        "    :param charset: string containing all desired characters to be represented.\n",
        "    :return: A tensorflow lookup table to convert integers to characters\n",
        "    \"\"\"\n",
        "    chars, indices = str_charset_to_lists(charset)\n",
        "\n",
        "    idx2char = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(\n",
        "            keys=tf.constant(indices, dtype=tf.int32),\n",
        "            values=tf.constant(chars, dtype=tf.string),\n",
        "            key_dtype=tf.int32,\n",
        "            value_dtype=tf.string\n",
        "        ),\n",
        "        default_value='',\n",
        "        name='idx2char_lookup'\n",
        "    )\n",
        "\n",
        "    return idx2char\n",
        "\n",
        "\n",
        "def pad_or_truncate(t, sequence_size=128):\n",
        "    \"\"\"\n",
        "    Pad or truncate a tensor to a fixed sequence length. Works for use in the tf.data api in graph mode.\n",
        "\n",
        "    :param t: The tensor to pad or truncate\n",
        "    :param sequence_size: The final sequence length of the tensor\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    dim = tf.size(t)\n",
        "    return tf.cond(tf.equal(dim, sequence_size), lambda: t,\n",
        "                   lambda: tf.cond(tf.greater(dim, sequence_size), lambda: tf.slice(t, [0], [sequence_size]),\n",
        "                                   lambda: tf.concat([t, tf.zeros(sequence_size - dim, dtype=tf.int32)], 0)))\n",
        "\n",
        "\n",
        "def merge_repeating_values(t):\n",
        "    \"\"\"\n",
        "    Merge repeating indices/characters in a tensor. Utilizes only tf.* functions which makes it\n",
        "    usable in graph mode.\n",
        "\n",
        "    :param t: The tensor to have repeated indices/characters merged\n",
        "    :return: A new tensor with repeating values merged\n",
        "    \"\"\"\n",
        "    t2 = tf.roll(tf.pad(t, [[0, 1]], constant_values=-1), -1, 0)[:tf.size(t)]\n",
        "    not_equal = tf.math.not_equal(t, t2)\n",
        "    indices = tf.where(not_equal)\n",
        "    return tf.reshape(tf.gather(t, indices), [-1])\n",
        "\n",
        "\n",
        "def str_to_idxs(string, char2idx, sequence_size):\n",
        "    \"\"\"\n",
        "    Perform the actual lookup to convert a string to its integer representation. This function also performs\n",
        "    padding according to the given sequence size. Works for use in the tf.data api in graph mode.\n",
        "\n",
        "    :param string: The string to be converted\n",
        "    :param char2idx: The tf lookup table\n",
        "    :param sequence_size: The final sequence length\n",
        "    :return: The converted string now in its integer representation\n",
        "    \"\"\"\n",
        "    idxs = tf.map_fn(lambda char: char2idx.lookup(char), tf.strings.unicode_split(string, 'UTF-8'), dtype=tf.int32)\n",
        "    return pad_or_truncate(idxs, sequence_size=sequence_size)\n",
        "\n",
        "\n",
        "def idxs_to_str(idxs, idx2char, merge_repeated=True):\n",
        "    \"\"\"\n",
        "    Perform the actual lookup to convert an integer to its string representation.\n",
        "    Works for use in the tf.data api in graph mode.\n",
        "\n",
        "    :param idxs: The idxs to be converted\n",
        "    :param idx2char: The tf lookup table\n",
        "    :param merge_repeated: Bool indicating whether or not to merge repeating values in the idx tensor\n",
        "    :return: The converted idxs now in its string representation\n",
        "    \"\"\"\n",
        "    if merge_repeated:\n",
        "        idxs = merge_repeating_values(idxs)\n",
        "\n",
        "    string = tf.map_fn(lambda idx: idx2char.lookup(idx), idxs, dtype=tf.string)\n",
        "    string = tf.strings.reduce_join(string)\n",
        "    return tf.strings.strip(string)\n",
        "\n",
        "\n",
        "def str_to_idxs_batch(batch, char2idx, sequence_size=128):\n",
        "    \"\"\"\n",
        "    Perform the same function as str_to_idxs, except a batch of strings are given as input\n",
        "\n",
        "    :param batch: A batch of strings as tensor, list, or numpy array\n",
        "    :param char2idx: The tf lookup table\n",
        "    :param sequence_size: The final sequence length of each string\n",
        "    :return: The converted strings now in its integer representation\n",
        "    \"\"\"\n",
        "    return tf.map_fn(lambda string: str_to_idxs(string, char2idx, sequence_size=sequence_size), batch,\n",
        "                     dtype=tf.int32)\n",
        "\n",
        "\n",
        "def idxs_to_str_batch(batch, idx2char, merge_repeated=True):\n",
        "    \"\"\"\n",
        "    Perform the same function as idxs_to_str, except a batch of idxs are given as input\n",
        "\n",
        "    :param batch: A batch of idxs as tensor, list, or numpy array\n",
        "    :param idx2char: The tf lookup table\n",
        "    :param merge_repeated: Bool indicating whether or not to merge repeating values in the idx tensor\n",
        "    :return: The converted idxs now in its string representation\n",
        "    \"\"\"\n",
        "    return tf.map_fn(lambda idxs: idxs_to_str(idxs, idx2char, merge_repeated=merge_repeated), batch,\n",
        "                     dtype=tf.string)\n",
        "\n",
        "def img_resize_with_pad(img_tensor, desired_size, pad_value=255):\n",
        "  \"\"\"\n",
        "  The standard tf.image.resize_with_pad function does not allow for specifying the pad value,\n",
        "  so we create a function with that capability here. Aspect ratio will be preserved.\n",
        "\n",
        "  :param img_tensor: The image tensor to be resized and padded\n",
        "  :param desired_size: The desired size (height, width)\n",
        "  :param pad_value: The value to pad the tensor with\n",
        "  \"\"\"\n",
        "  img_size = tf.shape(img_tensor)\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:\n",
        "      # Solve by height\n",
        "      new_height = desired_size[0]\n",
        "      new_width = int(desired_size[0] // img_ratio)\n",
        "  else:\n",
        "      new_height = int(desired_size[1] * img_ratio)\n",
        "      new_width = desired_size[1]\n",
        "      # Solve by width\n",
        "\n",
        "  resized_img = tf.image.resize(img_tensor, (new_height, new_width), method=tf.image.ResizeMethod.BICUBIC)\n",
        "\n",
        "  pad_height = desired_size[0] - new_height\n",
        "  pad_width = desired_size[1] - new_width\n",
        "\n",
        "  img_padded = tf.pad(resized_img, [[pad_height, 0], [0, pad_width], [0, 0]], constant_values=pad_value)\n",
        "\n",
        "  return img_padded\n",
        "\n",
        "\n",
        "def img_resize_with_pad_numpy(img, desired_size, pad_value=255):\n",
        "  \"\"\"\n",
        "  Same as img_resize_with_pad, except pillow and numpy are used to resize and pad the image\n",
        "  compared to the default tensorflow image operations.\n",
        "\n",
        "  :param img_tensor: The pillow image to be resized and padded\n",
        "  :param desired_size: The desired size (height, width)\n",
        "  :param pad_value: The value to pad the tensor with\n",
        "  \"\"\"\n",
        "  img_size = np.array(img).shape\n",
        "\n",
        "  img_ratio = img_size[0] / img_size[1]\n",
        "  desired_ratio = desired_size[0] / desired_size[1]\n",
        "\n",
        "  if img_ratio >= desired_ratio:  # Solve by height\n",
        "    new_height = desired_size[0]\n",
        "    new_width = int(desired_size[0] // img_ratio)\n",
        "  else:  # Solve by width\n",
        "    new_height = int(desired_size[1] * img_ratio)\n",
        "    new_width = desired_size[1]\n",
        "\n",
        "  img = np.array(img.resize((new_width, new_height)))\n",
        "\n",
        "  border_top = desired_size[0] - new_height\n",
        "  border_right = desired_size[1] - new_width\n",
        "\n",
        "  img = np.pad(img, [(border_top, 0), (0, border_right)], mode='constant', constant_values=pad_value)\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "def read_and_encode_image(img_path, img_size=(64, 1024)):\n",
        "  \"\"\"\n",
        "  Used by both encode_img_and_transcription (training) and encode_img_with_name (inference). This method\n",
        "  simply loads the image given a file path and performs the necessary encoding/resizing/transposing that\n",
        "  is necessary for use on the recognition model.\n",
        "\n",
        "  :param img_path: The path to the desired image\n",
        "  :param img_size: The size of the image after resizing/padding\n",
        "  :return: The encoded image in its tensor/integer representation\n",
        "  \"\"\"\n",
        "  img_bytes = tf.io.read_file(img_path)\n",
        "  img = tf.image.decode_image(img_bytes, channels=1, expand_animations=False)\n",
        "  img = img_resize_with_pad(img, img_size)\n",
        "  img = tf.image.per_image_standardization(img)\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "def read_and_encode_image_pillow(img_path, img_size=(64, 1024)):\n",
        "  \"\"\"\n",
        "  Same as read_and_encode_image function except using pillow to load the image rather than\n",
        "  default tensorflow image operations\n",
        "\n",
        "  :param img_path: The path to the desired image\n",
        "  :param img_size: The size of the image after resizing/padding\n",
        "  :return: The encoded image in its tensor/integer representation\n",
        "  \"\"\"\n",
        "  img = Image.open(img_path.numpy())\n",
        "  # img = img.convert('RGB')\n",
        "  img = img_resize_with_pad_numpy(img, img_size.numpy())\n",
        "  img = tf.constant(img, dtype=tf.float32)\n",
        "\n",
        "  return img\n",
        "\n",
        "\n",
        "def encode_img_and_transcription(img_path, transcription, char2idx, sequence_size=128, img_size: tuple = (64, 1024)):\n",
        "  \"\"\"\n",
        "  The actual function to map image paths and string transcriptions to its tensor/integer representation.\n",
        "\n",
        "  :param img_path: The path to the desired image\n",
        "  :param transcription: The transcription of the image in integer form\n",
        "  :param char2idx: The tf lookup table\n",
        "  :param sequence_size: The final sequence length for transcriptions\n",
        "  :param img_size: The size of the image after resizing/padding\n",
        "  :return: The image and transcription in their tensor/integer representations.\n",
        "  \"\"\"\n",
        "  img = tf.py_function(read_and_encode_image_pillow, [img_path, img_size], [tf.float32])\n",
        "  img = tf.transpose(img, [2, 1, 0])\n",
        "  line = str_to_idxs(transcription, char2idx, sequence_size)\n",
        "  return img, line\n",
        "\n",
        "\n",
        "def encode_img_with_name(img_path, img_size=(64, 1024)):\n",
        "    \"\"\"\n",
        "    Used to map img_paths to encoded images for inference. Returned is the encoded image and image name.\n",
        "\n",
        "    :param img_path: The file path to the image\n",
        "    :param img_size: The size of the image after resizing/padding\n",
        "    :return: The encoded image and image path\n",
        "    \"\"\"\n",
        "    img = read_and_encode_image(img_path, img_size)\n",
        "    return img, img_path\n",
        "\n",
        "\n",
        "def get_dataset_size(csv_path):\n",
        "    \"\"\"\n",
        "    The tf.data api has a hard time producing the the dataset size. The cardinality() method often\n",
        "    returns unknown even with the CsvDataset. This function uses pandas to get the length.\n",
        "\n",
        "    :param csv_path: The path to csv containing information about the dataset\n",
        "    :return: The size of the dataset\n",
        "    \"\"\"\n",
        "    return len(pd.read_csv(csv_path, sep='\\t', header=None, names=['img_path', 'transcription']))\n",
        "\n",
        "\n",
        "def get_encoded_dataset_from_csv(csv_path, char2idx, max_seq_size, img_size):\n",
        "    \"\"\"\n",
        "    Using the tf.data api, load the desired csv with img_path and transcription data, encode the images and\n",
        "    transcriptions for use on the recognition model and return the desired tf dataset.\n",
        "\n",
        "    :param csv_path: The path to the tab delimited csv file containing | Image Path | Transcription |\n",
        "    :param char2idx: The tf lookup table to map characters to their respective integer representation\n",
        "    :param max_seq_size: The final sequence length for transcriptions\n",
        "    :param img_size: The size of the image after resizing/padding (height, width).\n",
        "    :return: The tf dataset containing encoded images and their respective transcriptions\n",
        "    \"\"\"\n",
        "    path_sep = os.path.sep\n",
        "    path_prefix = tf.strings.join(csv_path.split('/')[:-1], path_sep)\n",
        "    return tf.data.experimental.CsvDataset(csv_path, ['img', 'trans'], field_delim='\\t', use_quote_delim=False).map(\n",
        "        lambda img_path, transcription: encode_img_and_transcription(\n",
        "            tf.strings.join([path_prefix, tf.strings.reduce_join(tf.strings.split(img_path, '/'), separator=path_sep)],\n",
        "                            separator=path_sep),\n",
        "            transcription, char2idx, max_seq_size, img_size),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "def get_encoded_inference_dataset_from_img_path(img_path, img_size):\n",
        "    \"\"\"\n",
        "    Using the tf.data api, load all images from the desired path and return a dataset containing encoded images\n",
        "    and the image name (without path or extension information).\n",
        "\n",
        "    :param img_path: The path to the directory containing images\n",
        "    :param img_size: The size of the image after resizing/padding (height, width)\n",
        "    :return: The tf dataset containing encoded images and their respective string names\n",
        "    \"\"\"\n",
        "    return tf.data.Dataset.list_files(img_path + '/*', shuffle=False).map(\n",
        "        lambda path: encode_img_with_name(path, img_size),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmnqfENWL5it"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "Here is the necessary code we need to build the model for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxAm6jr3L47I"
      },
      "source": [
        "class FullGatedConv2D(kl.Conv2D):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(FullGatedConv2D, self).__init__(filters=filters * 2, **kwargs)\n",
        "        self.nb_filters = filters\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = super(FullGatedConv2D, self).call(inputs)\n",
        "        linear = kl.Activation(\"linear\")(output[:, :, :, :self.nb_filters])\n",
        "        sigmoid = kl.Activation(\"sigmoid\")(output[:, :, :, self.nb_filters:])\n",
        "\n",
        "        return kl.Multiply()([linear, sigmoid])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_shape = super(FullGatedConv2D, self).compute_output_shape(input_shape)\n",
        "        return tuple(output_shape[:3]) + (self.nb_filters,)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(FullGatedConv2D, self).get_config()\n",
        "        config['nb_filters'] = self.nb_filters\n",
        "        del config['filters']\n",
        "        return config\n",
        "\n",
        "\n",
        "class Recognizer(Model):\n",
        "  def __init__(self, sequence_size=128, vocabulary_size=197):\n",
        "    super(Recognizer, self).__init__(name='flor_recognizer')\n",
        "\n",
        "    self.conv1 = tf.keras.Sequential(name='conv1')\n",
        "    self.conv1.add(kl.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv1.add(kl.PReklU(shared_axes=[1,2]))\n",
        "    self.conv1.add(kl.BatchNormalization(renorm=True))\n",
        "    self.conv1.add(FullGatedConv2D(filters=16, kernel_size=(3,3), padding=\"same\"))\n",
        "    \n",
        "    self.conv2 = tf.keras.Sequential(name='conv2')\n",
        "    self.conv2.add(kl.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv2.add(kl.PReklU(shared_axes=[1,2]))\n",
        "    self.conv2.add(kl.BatchNormalization(renorm=True))\n",
        "    self.conv2.add(FullGatedConv2D(filters=32, kernel_size=(3,3), padding=\"same\"))\n",
        "\n",
        "    self.conv3 = tf.keras.Sequential(name='conv3')\n",
        "    self.conv3.add(kl.Conv2D(filters=64, kernel_size=(2,4), strides=(2,4), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv3.add(kl.PReklU(shared_axes=[1,2]))\n",
        "    self.conv3.add(kl.BatchNormalization(renorm=True))\n",
        "    self.conv3.add(FullGatedConv2D(filters=64, kernel_size=(3,3), padding=\"same\", kernel_constraint=C.MaxNorm(4, [0,1,2])))\n",
        "    self.dropout1 = kl.Dropout(rate=0.3, name='dropout1')\n",
        "\n",
        "    self.conv4 = tf.keras.Sequential(name='conv4')\n",
        "    self.conv4.add(kl.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv4.add(kl.PReklU(shared_axes=[1,2]))\n",
        "    self.conv4.add(kl.BatchNormalization(renorm=True))\n",
        "    self.conv4.add(FullGatedConv2D(filters=128, kernel_size=(3,3), padding=\"same\", kernel_constraint=C.MaxNorm(4, [0,1,2])))\n",
        "    self.dropout2 = kl.Dropout(rate=0.3, name='dropout2')\n",
        "\n",
        "    self.conv5 = tf.keras.Sequential(name='conv5')\n",
        "    self.conv5.add(kl.Conv2D(filters=256, kernel_size=(2,4), strides=(2,4), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv5.add(kl.PReklU(shared_axes=[1,2]))\n",
        "    self.conv5.add(kl.BatchNormalization(renorm=True))\n",
        "    self.conv5.add(FullGatedConv2D(filters=256, kernel_size=(3,3), padding=\"same\", kernel_constraint=C.MaxNorm(4, [0,1,2])))\n",
        "    self.dropout3 = kl.Dropout(rate=0.3, name='dropout3')\n",
        "\n",
        "    self.conv6 = tf.keras.Sequential(name='conv6')\n",
        "    self.conv6.add(kl.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding=\"same\", kernel_initializer=\"he_uniform\"))\n",
        "    self.conv6.add(kl.PReklU(shared_axes=[1,2]))\n",
        "    self.conv6.add(kl.BatchNormalization(renorm=True))\n",
        "    \n",
        "    self.mp = kl.MaxPooling2D(pool_size=(1,2), strides=(1,2), padding=\"valid\", name='mp')\n",
        "\n",
        "    self.gru1 = tf.keras.Sequential(name='gru1')\n",
        "    self.gru1.add(kl.Bidirectional(kl.GRU(units=256, return_sequences=True, dropout=0.5)))\n",
        "    self.gru1.add(kl.Dense(units=512))\n",
        "    self.gru1.add(kl.PReklU())\n",
        "\n",
        "    self.gru2 = tf.keras.Sequential(name='gru2')\n",
        "    self.gru2.add(kl.Bidirectional(kl.GRU(units=256, return_sequences=True, dropout=0.5)))\n",
        "    self.gru2.add(kl.Dense(units=vocabulary_size))\n",
        "    \n",
        "  def call(self, x, training=False):\n",
        "    # CNN\n",
        "    out = self.conv1(x)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.dropout1(out, training=training)\n",
        "    out = self.conv4(out)\n",
        "    out = self.dropout2(out, training=training)\n",
        "    out = self.conv5(out)\n",
        "    out = self.dropout3(out, training=training)\n",
        "    out = self.conv6(out)\n",
        "\n",
        "    # MaxPool and Reshape\n",
        "    out = self.mp(out)\n",
        "    # out = tf.squeeze(out)\n",
        "    out = tf.reshape(out, (-1, out.shape[1], out.shape[2] * out.shape[3]))\n",
        "\n",
        "    # RNN\n",
        "    out = self.gru1(out)\n",
        "    out = self.gru2(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wcTBmEQTcKv"
      },
      "source": [
        "## Choose a Pre-trained Model\n",
        "\n",
        "Out of all of our pre-trained models, let's find the best model to start with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXtPQ2BzT0Q_"
      },
      "source": [
        "# First, load in all of our pre-trained models\n",
        "iam_model = Recognizer()\n",
        "iam_model.load_weights()\n",
        "\n",
        "rimes_model = Recognizer()\n",
        "rimes_model.load_weights()\n",
        "\n",
        "bentham_model = Recognizer()\n",
        "bentham_model.load_weights()\n",
        "\n",
        "models = [iam_model, rimes_model, bentham_model]\n",
        "\n",
        "# Take a subset of the dataset to use for testing\n",
        "dataset = get_inference_dataset_from_...\n",
        "\n",
        "# Metrics to help us select the best model \n",
        "mean_confidence = tf.keras.metrics.Mean(name=\"confidence\")\n",
        "best_model = None\n",
        "best_score = 1000\n",
        "\n",
        "# Iterate over each of the models\n",
        "for model in models:\n",
        "    mean_confidence.reset_states()\n",
        "\n",
        "    # Iterate over the subset of the dataset\n",
        "    for img, img_name in dataset:\n",
        "        output = model(img)\n",
        "        prediction, confidence = predict_with_confidence(output)\n",
        "    \n",
        "    if mean_confidence.result() < best_score:\n",
        "        best_model = model\n",
        "\n",
        "print('Best Model:', best_model.name)\n",
        "print('Confidence Score:', best_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McGtcqyMctVx"
      },
      "source": [
        "# Run through the dataset and see if there are any lines where we are highly\n",
        "# confident in our predictions\n",
        "model = best_model\n",
        "confidence_threshold = .4\n",
        "\n",
        "training_set = []\n",
        "labeling_set = []\n",
        "\n",
        "for img, img_name in dataset:\n",
        "    output = model(img)\n",
        "    prediction, confidence = predict_with_confidence(output)\n",
        "\n",
        "    if confidence > confidence_threshold:\n",
        "        training_set.append([img, img_name])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}